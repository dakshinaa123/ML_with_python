{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05a7a826",
   "metadata": {},
   "source": [
    "# DAY 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1c244",
   "metadata": {},
   "source": [
    "### Basic Functions and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd35440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training feature shape:  (120, 4)\n",
      "Training labels shape:  (120, 4)\n",
      "Training feature shape:  (120, 4)\n",
      "Training labels shape:  (120, 4)\n",
      "Accuracy: 1.0\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      1.00      1.00         9\n",
      "   virginica       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Load Iris Dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to Dataframe for easier handing\n",
    "df = pd.DataFrame(data=X, columns= iris.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "\n",
    "print('Training feature shape: ', X_train.shape)\n",
    "print('Training labels shape: ', X_train.shape)\n",
    "print('Training feature shape: ', X_train.shape)\n",
    "print('Training labels shape: ', X_train.shape)\n",
    "\n",
    "# Standarize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#Initialize the model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "#Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "#Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "#Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, target_names =iris.target_names)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\",report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "275207bb",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c1e00",
   "metadata": {},
   "source": [
    "#### 1. Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c919d7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After droping rows with missing values:\n",
      "       A    B    C\n",
      "3  4.0  4.0  4.0\n",
      "\n",
      " After dropping colums with missing values: \n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3]\n",
      "\n",
      " After imputing missing values: \n",
      "           A    B         C\n",
      "0  1.000000  3.0  1.000000\n",
      "1  2.000000  2.0  2.666667\n",
      "2  2.333333  3.0  3.000000\n",
      "3  4.000000  4.0  4.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Sample dataset with mising values\n",
    "data = {\n",
    "    'A' : [1,2,None,4],\n",
    "    'B' : [None,2,3,4],\n",
    "    'C' : [1,None,3,4]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Dropping Missing Values\n",
    "# Drop rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print('After droping rows with missing values:\\n ',df_dropped)\n",
    "\n",
    "# Drop columns with missing values\n",
    "df_dropped_cols = df.dropna(axis=1)\n",
    "print('\\n After dropping colums with missing values: \\n',df_dropped_cols)\n",
    "\n",
    "# Replacing Missing Values with Mean\n",
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
    "print('\\n After imputing missing values: \\n',df_imputed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af4a2d6",
   "metadata": {},
   "source": [
    "#### 2. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed02d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Standarization: \n",
      "           A         B\n",
      "0 -1.341641 -1.341641\n",
      "1 -0.447214 -0.447214\n",
      "2  0.447214  0.447214\n",
      "3  1.341641  1.341641\n",
      "\n",
      "After Normalization: \n",
      "           A         B\n",
      "0 -1.341641 -1.341641\n",
      "1 -0.447214 -0.447214\n",
      "2  0.447214  0.447214\n",
      "3  1.341641  1.341641\n"
     ]
    }
   ],
   "source": [
    "# Standardization\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'A' : [1,2,3,4],\n",
    "    'B' : [2,3,4,5]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Standarize features\n",
    "scaler = StandardScaler()\n",
    "df_standardized = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "print('\\nAfter Standarization: \\n',df_standardized)\n",
    "\n",
    "# Normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Normalize features to the range [0,1]\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df),columns = df.columns)\n",
    "print('\\nAfter Normalization: \\n',df_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45a6d2",
   "metadata": {},
   "source": [
    "#### Encoding Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0241035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After Label Encoding: \n",
      "   Category  Category_Encoder\n",
      "0        A                 0\n",
      "1        B                 1\n",
      "2        A                 0\n",
      "3        C                 2\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Sample dataset with categorical data\n",
    "data = {'Category': ['A','B','A','C']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encode categorical data as numbers\n",
    "label_encoder = LabelEncoder()\n",
    "df['Category_Encoder'] = label_encoder.fit_transform(df['Category'])\n",
    "print('\\nAfter Label Encoding: \\n',df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a8e8e9",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8698f69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After one-hot encoding: \n",
      "   Category  Category_A  Category_B  Category_C\n",
      "0        A         1.0         0.0         0.0\n",
      "1        B         0.0         1.0         0.0\n",
      "2        A         1.0         0.0         0.0\n",
      "3        C         0.0         0.0         1.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "data = {'Category': ['A', 'B', 'A', 'C']}\n",
    "df = pd.DataFrame(data)\n",
    "# One-hot encode categorical data\n",
    "one_hot_encoder = OneHotEncoder (sparse_output=False)\n",
    "encoded = one_hot_encoder.fit_transform(df [[ 'Category']])\n",
    "# Create a DataFrame with one-hot encoded columns\n",
    "encoded_df = pd.DataFrame (encoded, columns=one_hot_encoder.get_feature_names_out(['Category']))\n",
    "df_one_hot_encoded = pd.concat([df, encoded_df], axis=1)\n",
    "print(\"\\nAfter one-hot encoding: \\n\", df_one_hot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ca0e2",
   "metadata": {},
   "source": [
    "### Splitting and Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9cc84689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split # Sample dataset\n",
    "data = {\n",
    "    'Feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Feature2': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "     'Target': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a088f6ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: \n",
      "    Feature1  Feature2\n",
      "5         6        16\n",
      "0         1        11\n",
      "7         8        18\n",
      "2         3        13\n",
      "9        10        20\n",
      "4         5        15\n",
      "3         4        14\n",
      "6         7        17\n",
      "Training labels: \n",
      " 5    1\n",
      "0    0\n",
      "7    1\n",
      "2    0\n",
      "9    1\n",
      "4    0\n",
      "3    1\n",
      "6    0\n",
      "Name: Target, dtype: int64\n",
      "Testing labels: \n",
      " 8    0\n",
      "1    1\n",
      "Name: Target, dtype: int64\n",
      "Testing features: \n",
      "    Feature1  Feature2\n",
      "8         9        19\n",
      "1         2        12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Sample dataset\n",
    "data = {\n",
    "    'Feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Feature2': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    'Target': [0, 1, 0, 1, 0, 1, 0, 1, 0, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "#Features and target variable\n",
    "X = df[['Feature1', 'Feature2']] # Features\n",
    "y=df['Target'] # Target variable\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training features: \\n\", X_train)\n",
    "print(\"Training labels: \\n\", y_train)\n",
    "print(\"Testing labels: \\n\", y_test)\n",
    "print(\"Testing features: \\n\", X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1abf2bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (120, 4)\n",
      "Testing features shape: (30, 4)\n",
      "Training labels shape: (120,)\n",
      "Testing labels shape: (30,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Load the Iris dataset\n",
    "iris\n",
    "load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "#Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training features shape:\", X_train.shape) \n",
    "print(\"Testing features shape:\", X_test.shape) \n",
    "print(\"Training labels shape:\", y_train.shape) \n",
    "print(\"Testing labels shape:\", y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
